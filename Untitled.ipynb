{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from time import time\n",
    "\n",
    "# Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Reshape, UpSampling2D, Conv2DTranspose, GlobalAveragePooling1D, Softmax\n",
    "from keras.losses import kullback_leibler_divergence\n",
    "import keras.backend as K\n",
    "\n",
    "# local\n",
    "from dataloader import load_data\n",
    "from DATC import DATC\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train)= load_data('Computers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "n_clusters = len(np.unique(y_train))\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrain_optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datc= DATC(n_clusters=n_clusters,          # cluster个数\n",
    "              input_dim=X_train.shape[-1],          # 特征数，一般是单变量时序聚类，此处一般是1\n",
    "              timesteps=X_train.shape[1],\n",
    "              n_filters=50,             # 1D CNN中filter的个数\n",
    "              kernel_size=10,         # kernel的大小\n",
    "              strides=1,                 # 步长\n",
    "              pool_size=10,             # pooling的大小\n",
    "              n_units=[50,1,10],                 # LSTM中神经元个数\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda2/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datc.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ClusteringModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_seq (InputLayer)       (None, 720, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 720, 50)           550       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 720, 50)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 72, 10)            4880      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 72, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1442      \n",
      "_________________________________________________________________\n",
      "sm (Softmax)                 (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,872\n",
      "Trainable params: 6,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "datc.cModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AE0\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_seq0 (InputLayer)      (None, 720, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 50)           550       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 720, 50)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 72, 50)            40400     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 72, 1)             416       \n",
      "_________________________________________________________________\n",
      "latent (LeakyReLU)           (None, 72, 1)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 72, 1, 1)          0         \n",
      "_________________________________________________________________\n",
      "upsampling (UpSampling2D)    (None, 720, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2dtranspose (Conv2DTrans (None, 720, 1, 1)         11        \n",
      "_________________________________________________________________\n",
      "output_seq (Reshape)         (None, 720, 1)            0         \n",
      "=================================================================\n",
      "Total params: 41,377\n",
      "Trainable params: 41,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "datc.autoencoders[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"softmax_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "softmax_input (InputLayer)   (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1442      \n",
      "_________________________________________________________________\n",
      "sm (Softmax)                 (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,442\n",
      "Trainable params: 1,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "datc.softMax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"before_softmax\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_seq (InputLayer)       (None, 720, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 720, 50)           550       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 720, 50)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 72, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 72, 10)            4880      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 72, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 720)               0         \n",
      "=================================================================\n",
      "Total params: 5,430\n",
      "Trainable params: 5,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "datc.TAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.152 --> 0.146 --> 0.144 --> 0.144 --> 0.143 --> 0.143 --> 0.143 --> \n",
      "Begin to pretrain cModel\n",
      "WARNING:tensorflow:From /anaconda2/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.6529\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5559\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4275\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3272\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2464\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2058\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1731\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1570\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1640\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.1430\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1301\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1571\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1408\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1305\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1190\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.1166\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1138\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1095\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1133\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1060\n",
      "Begin to pretrain AE 0\n",
      "Epoch 1/20\n",
      "325/325 [==============================] - 4s 13ms/step - loss: 0.9637\n",
      "Epoch 2/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.8560\n",
      "Epoch 3/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.7741\n",
      "Epoch 4/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.6982\n",
      "Epoch 5/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.6274\n",
      "Epoch 6/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.5643\n",
      "Epoch 7/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.5146\n",
      "Epoch 8/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.4732\n",
      "Epoch 9/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.4381\n",
      "Epoch 10/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.4087\n",
      "Epoch 11/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.3836\n",
      "Epoch 12/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.3623\n",
      "Epoch 13/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.3444\n",
      "Epoch 14/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.3292\n",
      "Epoch 15/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.3161\n",
      "Epoch 16/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.3049\n",
      "Epoch 17/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.2955\n",
      "Epoch 18/20\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.2872\n",
      "Epoch 19/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.2798\n",
      "Epoch 20/20\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.2736\n",
      "Begin to pretrain AE 1\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 7s 38ms/step - loss: 0.9354\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.8278\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.7484\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.6865\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.6286\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.5778\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.5328\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 0.4921\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.4573\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.4275\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.4030\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.3806\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3620\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3438\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3275\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3139\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3025\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2922\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2828\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2750\n",
      "-----------Pretrain End.-----------\n",
      "Pretrain time:  89.1279821395874\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "datc.pretrain(X_train,n_clusters,pretrain_optimizer,\n",
    "                    20,64,'results/tmp')\n",
    "print('Pretrain time: ', (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------debug------------\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, ?) (?, 2)\n",
      "Tensor(\"sm_target_1:0\", shape=(?, ?), dtype=float32) Tensor(\"sm_1/Softmax:0\", shape=(?, 2), dtype=float32)\n",
      "--------------debug------------\n"
     ]
    }
   ],
   "source": [
    "datc.compile('adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
